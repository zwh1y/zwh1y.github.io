<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>3D Object</title>
      <link href="/2022/05/11/SRT3D/"/>
      <url>/2022/05/11/SRT3D/</url>
      
        <content type="html"><![CDATA[<h3 id="abstract："><a href="#abstract：" class="headerlink" title="abstract："></a>abstract：</h3><ol><li><p>基于区域的方法很火热，但是计算成本高，需求资源多。</p></li><li><p>我们提出了<strong>SRT3D</strong>可以减小效率上的差距</p><ol><li>我们的模型认为图像信息会沿着对应线稀疏（correspondence lines），对应线会模拟物体的位置概率</li><li>引入smoothed step functions（平滑阶跃函数，西瓜书看到的翻译），用于考量定义的全局和局部的不确定性，对产生的概率公式进行分析</li><li>使用预渲染的稀疏视点模型（sparse viewpoint model）为对象姿势创建联合后验概率。</li><li>使用牛顿…优化</li></ol></li><li><p>运行时间和质量比现有技术好，尤其是噪声和杂乱图像。</p></li></ol><h3 id="Introduction"><a href="#Introduction" class="headerlink" title="Introduction"></a>Introduction</h3><ol><li>计算机是觉得重要任务之一：跟踪三维空间中的刚体并预测其六自由度。在虚拟现实和机器人都有应用</li><li>给定连续的图像帧，3D目标追踪的目标是：估计对象相对于相机的旋转和平移。</li><li>概述现有技术、相关工作、我们的方法和贡献</li></ol><h4 id="1-1-3D-Object-Tracking"><a href="#1-1-3D-Object-Tracking" class="headerlink" title="1.1 3D Object Tracking"></a>1.1 3D Object Tracking</h4><p>主流方法：</p><table><thead><tr><th>3D目标追踪</th><th>优点</th><th>缺点</th></tr></thead><tbody><tr><td>key-points</td><td>应用广泛、最在不同阶段引入了深度学习</td><td>需要丰富的纹理（rich texture）</td></tr><tr><td>explicit  edges</td><td>提供格外的信息来源</td><td>在复杂场景容易失败（cluttered sccenes）</td></tr><tr><td>direct  optimization</td><td>优化了光度误差（photometric error）</td><td>需要丰富的纹理（rich texture）</td></tr><tr><td></td><td></td><td>motion blur会改变纹理的边缘导致格外问题。</td></tr><tr><td>deep  learning</td><td>使用CNNs考量完整图像信息，效果好</td><td>少数算法能够实时进行、每秒少于30帧、需要高端GPUs、耗时、需要有纹理的3D模型</td></tr><tr><td>depth  information</td><td>使用深度相机（depth cameras）结合深度和RGB信息，总体可以得到更好的效果</td><td>很多应用中，不能使用深度传感器。</td></tr><tr><td></td><td></td><td>由于硬件、表面距离、表面特征和照明条件难以得到算法需要的高质量图像</td></tr><tr><td>image  regions</td><td>在复杂场景中追踪对象、仅使用单目RGB相机和无纹理3D模型<br />过去方法计算成本高，但是我们克服了这一缺点<br />解决了动态模糊的问题，可以快速移动的物体</td><td></td></tr></tbody></table><h4 id="1-2-Related-Work"><a href="#1-2-Related-Work" class="headerlink" title="1.2 Related Work"></a>1.2 Related Work</h4><ol><li>基于区域的方法使用图像统计以区分目标所对应的前景和背景。<ol><li>目标：找到最能展示图像分割的目标姿势以及轮廓。</li><li>潜力：挑战背景下，鲁棒追踪</li><li>最终，PWP3D将分割和追踪结合的方法以及像素级后验成员身份（ the pixel-wise posterior membership）结合，是使用水平集姿势的实时算法。它是几乎所有先进的基于区域的方法的基础。</li></ol></li><li>大量算法对PWP3D进行了改进，如结合格外信息、拓展分割模型、提高效率、使用基于ICP的算法拓展能量函数、使用3D符号距离函数将藕和区域与深度信息结合到概率公式中、使用像素强度值或描述区域（descriptor fields）直接优化目标纹理、基于边缘的使用一个轮廓部分模型的技术。。。一直在介绍不同的技术，但是都只提一句话。</li><li>最后引入自己的技术</li></ol><h4 id="1-3-Contribution"><a href="#1-3-Contribution" class="headerlink" title="1.3 Contribution"></a>1.3 Contribution</h4><ol><li><p>我们致力于开发SRT3D，一种高效、稀疏的基于区域的跟踪方法。为了降低复杂性，我们使用区域信息和采用全局分割模型。我们在先前工作的基础上考虑沿对应线的稀疏图像信息，牛顿优化与Tikhonov正则化被用来估计对象的姿态。</p></li><li><p>我们的贡献：</p><ol><li>对应线的形式定义和描述轮廓位置的概率模型数学推导</li><li>对全局和局部不确定性建模的新的平滑阶跃函数</li><li>参数对后验概率分布的影响</li><li>全局和局部优化策略以及局部一阶导数的新近似</li></ol></li><li><p>之后先将对应线模型的建模，再将算法实现细节。我们的算法在RBOT和OPT上比现有技术效果和质量都更好</p></li></ol><h3 id="Correspondence-Line-Model"><a href="#Correspondence-Line-Model" class="headerlink" title="Correspondence Line Model"></a>Correspondence Line Model</h3><ol><li>对应线的形式化数学定义</li><li>考虑将对应线分割为前景和背景的概率模型</li><li>拓展模型和提供离散比例公式</li><li>新的平滑阶跃函数以及其配置是如何影响轮廓位置的后验概率的</li></ol><h4 id="2-1-Correspondence-Lines"><a href="#2-1-Correspondence-Lines" class="headerlink" title="2.1 Correspondence Lines"></a>2.1 Correspondence Lines</h4><ol><li>我们考虑沿对应线稀疏地处理像素值（类似于ICP，先定义对应关系，再优化）</li><li>建立模型：根据传统的图像的定义建立对应线的定义，并表示出二者关系</li></ol><p>$$<br>\mathbf {l} \left (r \right ) &#x3D; I \left ( \mathbf {c} +r \mathbf {n} \right ) \tag {1}<br>$$</p><h4 id="2-2-Probabilistic-Model"><a href="#2-2-Probabilistic-Model" class="headerlink" title="2.2 Probabilistic Model"></a>2.2 Probabilistic Model</h4><ol><li>提出了一个概率模型，用于将对应线分割为前景区域$\omega_f$和背景区域$\omega_b$。这相当于分割二维图像到区域 到$\Omega_f$和$\Omega_b$</li><li>我们假定前景到背景只有一个过渡（translation），通过线中心（line center） $\mathbf{c}$和相对（$\mathbf{c}$）距离$d$</li></ol><p>从对应线上的单个像素的形成开始推导，联合概率分布如下<br>$$<br>p\left(r, \mathbf{y}, d, m\right ) &#x3D; p\left (r\space| \space d, m\right )p(\mathbf{y} \space |\space m )p(m)p(d) \tag{2}<br>$$</p><blockquote><p>符号解释：<br>$r$：line coordinate（线坐标）</p><p>$\mathbf{y}$：image values（图像值）这里应该是单个像素的值</p><p>$d$：contour distance 相对于线中心$c$的距离</p><p>$m$：$m\in \left { m_f,m_b \right } $ 表示前景或者背景的模型参数</p></blockquote><p>将条件设置为$y$：<br>$$<br>p\left(r, d, m \space | \space \mathbf{y} \right ) &#x3D;<br>p\left (r\space| \space d, m\right )<br>p(m\space |\space \mathbf{y} )<br>p(d) \tag{3}<br>$$</p><blockquote><p>推导过程：</p><p>由于$P(X,Y) &#x3D; P(X)P(X\space |\space Y)$</p><ol><li>$p\left (r\space| \space d, m\right )p(\mathbf{y} \space |\space m )p(m)p(d)<br>&#x3D; p(\mathbf{y} )p(r,d,m\space |\space \mathbf{y} )$</li><li>$p(r,d,m\space |\space \mathbf{y} )<br>&#x3D; \frac{p\left (r\space| \space d, m\right )p(\mathbf{y} \space |\space m )p(m)p(d)<br>}{p(\mathbf{y} )} $</li><li>$\frac{(\mathbf{y} \space |\space m )p(m)<br>}{p(\mathbf{y} )} &#x3D; p(m \space | \space \mathbf{y})$</li><li>$p\left(r, d, m \space | \space \mathbf{y} \right ) &#x3D;<br>p\left (r\space| \space d, m\right )<br>p(m\space |\space \mathbf{y} )<br>p(d)$</li><li>得证</li></ol></blockquote><p>使用贝叶斯和边缘化覆盖$m$来计算像素级后验概率</p><p>$p(\mathbf{y} \space |\space m_f)$和$p(\mathbf{y} \space |\space m_b)$是概率分布，分别描述一个特定的颜色值属于前景区域或背景区域的可能性有多大。可以通过前景区域和后景区域的颜色分布直方图来计算（详见4.2）<br>$$<br>p(m_i \space | \space \mathbf{y}) &#x3D; \frac{p(\mathbf{y} \space |\space m_i)p(m_i)}<br>{ {\textstyle \sum_{j \in { f,b}}^{}}p(\mathbf{y}\space | \space m_j )p(m_j) } ,<br>\space i \in {f, b} \tag{4}<br>$$</p><blockquote><p>同样可以用$P(X,Y) &#x3D; P(X)P(X\space |\space Y)$推出</p></blockquote><p>沿对应线前景和背景的可能性相等$p(m_f) &#x3D; p(m_b)$<br>$$<br>p(m_i \space | \space \mathbf{y}) &#x3D;<br>\frac{p(\mathbf{y} \space |\space m_i)}<br>{p(\mathbf{y}\space | \space m_f )+p(\mathbf{y}\space |\space  m_b) } ,<br>\space i \in {f, b} \tag{5}<br>$$<br>基于（3），边缘化覆盖$m$和$d$在条件$r$下的后验概率<br>$$<br>p(d \space | \space r ,\mathbf{y} ) &#x3D;<br>\frac{1}{p(r)}<br>\sum_{i \in {f, b}}^{}<br>p(r \space |\space d,m_i)p(m_i \space |\space \mathbf{y} )p(d) \tag{6}<br>$$<br>为了计算整个对应线域$\omega$上的后验概率，假设像素独立，基于（6）<br>$$<br>p(d \space | \space \omega ,\mathbf{l} ) \propto<br>\prod_{r \in \omega}^{}<br>\sum_{i \in {f, b}}^{}<br>p(r \space |\space d,m_i)p(m_i \space |\space \mathbf{l}(r) ) \tag{7}<br>$$</p><blockquote><p>$p(r)$和$p(d)$看作是常数所以删除</p><p>这是一个近似的假设，得到的结果十分接近真实值</p><p>条件线坐标概率$p(r \space |\space d,m_i)$在2.4提到，这个概率模型描述了从图像中给定信息的形状内核（shape kernel）的概率</p><p>公式（7）提供了等高线距离数据与对应线的概率。</p></blockquote><h4 id="2-3-Discrete-Scale-Space-Formulation"><a href="#2-3-Discrete-Scale-Space-Formulation" class="headerlink" title="2.3 Discrete Scale-Space Formulation"></a>2.3 Discrete Scale-Space Formulation</h4><table><thead><tr><th></th><th>复杂度</th><th>用途</th></tr></thead><tbody><tr><td>$p(d \space</td><td>\space \omega ,\mathbf{l} )$</td><td>quadratic（平方级）每一个d都要在整个域$\omega$</td></tr><tr><td>$p(m \space</td><td>\space \mathbf{y})$</td><td>linear（线性级）</td></tr></tbody></table><p>从分布转变为像素级后验概率可以提高计算效率</p><p>此外，对对应线进行归一化处理也是有利的，可以确保指向一条对应线的线段中心的线坐标$r$指向所有对应线的线段中心。 （a line coordinate pointing to a segment center for one correspondence line points to a segment  center  for all  correspondence  lines）</p><blockquote><p>我的理解：???</p></blockquote><p> 这种统一的形式可以用于平滑步骤函数值的预计算，以进一步提高效率</p><p>基于先前的研究，我们将多个像素结合至线段中。离散空间尺度公式将沿对应线的连续空间投影至独立于对应线位置和方向的离散空间，如图3</p><p>同一个颜色表示一个segment（线段），蓝色和黄色的点表示segment的中心和对应的离散化后的值</p><p>偏移量∆r的选择要确保标度空间中的离散值对所有对应线都是一样的。在这个例子中，∆r指向像素之间最接近的边缘。</p><p><img src="https://s3.bmp.ovh/imgs/2022/05/08/52d7334d49e20b74.png" class="lazyload" data-srcset="https://s3.bmp.ovh/imgs/2022/05/08/52d7334d49e20b74.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="><br>$$<br>r_s &#x3D; (r - \Delta r) \frac{\overline{n} }{s}  \tag{8}<br>$$</p><p>$$<br>d_s &#x3D; (d - \Delta r) \frac{\overline{n} }{s}  \tag{9}<br>$$</p><blockquote><p>$s$：合成为一段线段segment的像素比例（数量）</p><p>$\overline{n} &#x3D; max (|n_x|,|n_y|)$：将对应线投影到最近的水平或垂直图像坐标的主要的绝对法向分量</p><p>$\Delta r \in R$：从对应线中心$c$到定义的像素位置的距离（c所在的像素相邻两个像素中，c更接近的那个边缘到c的距离）</p><p>我的理解：<br>根据之前的内容的上述公式，以及d的定义：d是相对于中心点c的距离。我们可以理解为：假设r（line coordinate）为距离中心点c的距离。</p><p>这里就可以很好的解释$r&#x2F;d_s$减去偏移量$\Delta r$乘以$\frac{\overline{n}}{s}$这一映射关系</p><p>例如：图示的s为2（两个像素构成一个segment），$\overline{n}$为$n_x$（对应线距离水平线投影更近）。从最右边的黄色点来看，减去偏移量后，即$r - \Delta r$为3个单位像素（线坐标下），$n_x$为3，$\frac{\overline{n}}{s}$为1.5，那么对应到$r_s$中，坐标即为1.5如图所示。</p></blockquote><p>根据公式（7），离散尺度空间中的后验概率计算如下：<br>$$<br>p(d_s \space | \space \omega_s ,\mathbf{l}<em>s ) \propto<br>\prod</em>{r_s \in \omega_s}^{}<br>\sum_{i \in {f, b}}^{}<br>p(r_s \space |\space d_s,m_i)p(m_i \space |\space \mathbf{l_s}(r_s) ) \tag{10}<br>$$</p><blockquote><p>$\omega_s$：放缩后到对应线域</p><p>$\mathbf{s} &#x3D; \mathbf{l}_s(r_s)$：一个集值函数映射，它从按比例排列的线坐标映射到线段$s$，这是一个最接近$s$(和上文是一个意思)像素值$y$的集合</p></blockquote><p>类似于公式（5），我们假设像素间具有独立性，分段后验可以被定义为：<br>$$<br>p(m_i \space | \space \mathbf{s}) &#x3D;<br>\frac{\prod_{\mathbf{y} \in \mathbf{s} }p(\mathbf{y} \space |\space m_i)}<br>{\prod_{\mathbf{y} \in \mathbf{s} }p(\mathbf{y}\space | \space m_f )+<br>\prod_{\mathbf{y} \in \mathbf{s} }p(\mathbf{y}\space |\space  m_b) }<br>,\space i \in {f, b}<br>\tag{11}<br>$$<br>这个推导公式，允许使用放缩参数$s$设置线段尺寸和调整准确性和效率之间的取舍，来有效覆盖对应线域$\omega$</p><p>（之后的公式省略了下标s，但是定义和推导对原始空间和离散化空间都有效）</p><h4 id="2-4-Smoothed-Step-Functions"><a href="#2-4-Smoothed-Step-Functions" class="headerlink" title="2.4 Smoothed Step Functions"></a>2.4 Smoothed Step Functions</h4><p>目标：对线坐标的条件概率$p(r|d, m_f)$$p(r|d, m_b)$进行建模，因此提出了不同的平滑阶跃函数$h_f$和$h_b$</p><p>先前的工作：验证了双曲正切曲线会导致后验概率$p(d|\omega , l)$的<strong>高斯分布</strong></p><p>作用：平滑斜率用于模拟与前景和背景过渡的确切位置有关的<strong>局部</strong>不确定性</p><p>错误的假设：给一个模型$m$和轮廓距离$d$，我们就可以根据$h$函数预测线坐标$r$属于轮廓线的哪一边，但是在实际应用中是错误的</p><p>存在的问题：</p><pre><code>1. 等式（5）仍是对真实世界的不完美简化1. 统计模型未考虑图像噪声或快速外观变化，这可能导致颜色直方图中尚未出现的像素颜色1. 由于不完美的分割而被错误分类的像素，然后被分配到错误的颜色直方图1. 一个纯粹依赖像素颜色的统计模型是否足以捕捉现实世界中的所有统计效果，并且能够完美地预测模型$m$</code></pre><p>将上述问题考虑以及前景后景建模的<strong>恒定的全局</strong>不确定性<br>$$<br>h_f(x)&#x3D;\frac{1}{2}-\alpha _h tanh \left (\frac{x}{2s_h}  \right ) \tag{12}<br>$$</p><p>$$<br>h_b(x)&#x3D;\frac{1}{2}+\alpha _h tanh \left (\frac{x}{2s_h}  \right ) \tag{13}<br>$$</p><p>振幅参数$\alpha _h \in \left[0,0.5 \right]$添加到仅考虑坡度参数$s_h \in R^{+}$的原始定义中</p><blockquote><p> 对于$\alpha$的另一种解释：</p><p> 我们假设模型$m$扩展第三类$m_n$，该类$m_n$考虑独立于前景$\omega _f$和后景$\omega _b$的外部影响。对于这个场景，我们可以证明$p(m_f) &#x3D;p(m_b)&#x3D;\alpha $和$p(m_n)&#x3D;1-2\alpha$。</p><p> 根据这种解释，振幅参数因此允许我们设置一个像素的颜色由前景或背景模型生成的概率，与其他一些被视为噪声的影响形成对比。</p><p> 这再次表明，振幅参数α能够模拟恒定的全局不确定性。</p><p> 请注意，在这种情况下，收敛到0或1的原始平滑阶跃函数用于计算$p(r|d,m_f)$和$p(r|d_m)$，而噪声模型采用恒定函数$p(r|d,m_n)&#x3D;\frac{1}{2}$。</p><p> 附录A中给出了该扩展模型的详细推导及其与等式（12）和（13）中函数使用等价性的证明。</p></blockquote><h4 id="2-5-Posteior-Probability-Distrubution"><a href="#2-5-Posteior-Probability-Distrubution" class="headerlink" title="2.5 Posteior Probability Distrubution"></a>2.5 Posteior Probability Distrubution</h4><p>考虑到平滑阶跃函数$h_f和h_b$建立了条件线坐标概率模型$p(r | d,m_f)和p(r | d,m_b)$，则等式（7）中后验概率分布的最终表达式可以写成<br>$$<br>p(d \space | \space \omega ,\mathbf{l} ) \propto<br>\prod_{r \in \omega}^{}<br>h_f(r-d)p_f(r) + h_b(r-d)p_b(r)<br> \tag{14}<br>$$</p><blockquote><p> 缩写：$p_f(r)&#x3D;p(m_f \space |\space  \mathbf{l}(r))和p_b(r)&#x3D;p(m_b \space |\space  \mathbf{l}(r))$</p></blockquote><p>假设轮廓在对应线中心和像素级后验概率$p_f和p_b$的阶跃函数</p><p>阶跃函数的假设很好地反映了现实世界中的实验，实验表明，在大多数情况下，前景和后景之间存在明显的分离</p><p>对公式取对数并关于$d$求一阶导，假设具有无穷小像素的连续函数。基于附录B，封闭解如下：<br>$$<br>\frac{\partial ln(p(d \space | \space \omega, \mathbf{l} ))}{\partial d} &#x3D;<br>-2tanh^{-1}\left (  2 \alpha _h tanh \left ( \frac{d}{2s_h}  \right )\right )<br>\tag{15}<br>$$<br>满足$\alpha _h&#x3D;\frac{1}{2}$和$s_h \to 0$两种情况时，公式（15）可以简化，我们能计算后验概率分布的闭式解。</p><p>$\alpha _h&#x3D;\frac{1}{2}$时，我们获得了我们之前方法的平滑阶跃函数，公式（12）（13），后验概率分布会产生完美的高斯分布<br>$$<br>p(d \space | \space \omega ,\mathbf{l} ) &#x3D;<br>\frac{1}{\sqrt[]{2\pi s_h} }exp\left ( -\frac{d^2}{2s_h}  \right )   \tag{16}<br>$$<br>其中斜率参数$s_h$等于方差。在$s_h \to 0$的情况下，这导致了$h_f$和$h_b$的尖锐阶梯函数，后验概率分布成为一个完美的拉普拉斯分布<br>$$<br>p(d \space | \space \omega ,\mathbf{l} ) &#x3D;<br>\frac{1}{2b} exp\left ( -\frac{|d|}{b\ }  \right )   ,<br>b&#x3D;\frac{1}{2tanh^-1(2 \alpha _h)}<br>\tag{17}<br>$$<br>附录C中有详细推导</p><p>![image-20220424142755366](..&#x2F;..&#x2F;..&#x2F;..&#x2F;Library&#x2F;Application Support&#x2F;typora-user-images&#x2F;image-20220424142755366.png)</p><p><img src="https://s3.bmp.ovh/imgs/2022/05/08/f0e37a17f34ea0b5.png" class="lazyload" data-srcset="https://s3.bmp.ovh/imgs/2022/05/08/f0e37a17f34ea0b5.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>拉普拉斯分布（蓝色）有明显的峰值，高斯分布（黄色）有一个平滑的最大值，附近的值有类似的高概率</p><p>从图像中可以知道，$s_h$控制<strong>局部不确定性</strong>（大量的值d可能等于多少），$\alpha _h$控制<strong>全局不确定性</strong>（控制与周围环境相比的峰值大小）</p><h3 id="Region-Based-3D-Tracking"><a href="#Region-Based-3D-Tracking" class="headerlink" title="Region-Based 3D Tracking"></a>Region-Based 3D Tracking</h3><p>内容：</p><ol><li>定义数学概念</li><li>对稀疏视点模型的描述，这个模型避免了在跟踪过程中对三维模型的渲染</li><li>将这种几何学表示与对应线模型结合，制定出与姿势有关的联合后验概率</li><li>该概率通过牛顿优化和Tikhonov正则化实现最大化。 </li><li>我们为牛顿方法定义所需的梯度向量和Hessian矩阵。因此，我们区分了全局和局部优化，以确保快速融合和高精确度。</li></ol><h4 id="3-1-Preliminaries-前言"><a href="#3-1-Preliminaries-前言" class="headerlink" title="3.1 Preliminaries 前言"></a>3.1 Preliminaries 前言</h4><p>定义：3D模型点$\mathbf{X} &#x3D; [X \space Y \space Z]^{T}\in R^{3}$ 其次形式：$\widetilde{\mathbf{X}}  &#x3D; [X \space Y \space Z \space 1]^{T}\in R^{3}$</p><blockquote><p>齐次坐标就是将一个原本是n维的<a href="https://baike.baidu.com/item/%E5%90%91%E9%87%8F/1396519">向量</a>用一个n+1维向量来表示，是指一个用于投影几何里的<a href="https://baike.baidu.com/item/%E5%9D%90%E6%A0%87%E7%B3%BB%E7%BB%9F/4725756">坐标系统</a>，如同用于<a href="https://baike.baidu.com/item/%E6%AC%A7%E6%B0%8F%E5%87%A0%E4%BD%95/2650993">欧氏几何</a>里的笛卡儿坐标一般</p><p>引入齐次坐标可以让放缩变换变得更加统一简单。例如：平移是矩阵加法，而升维之后可以用矩阵乘法实现</p></blockquote><p>对于3D模型点$\mathbf{X}$向图像空间的投影，我们假设图像不失真，并使用针孔相机模型<br>$$<br>x &#x3D; \pi (\mathbf{X} )&#x3D;\begin{bmatrix}<br> \frac{X}{Z}f_x + p_x \ \frac{X}{Z} f_y + p_y<br>\end{bmatrix}<br>\tag{18}<br>$$</p><blockquote><p> 焦距$f_x和f_y$、关键点（principal point）$p_x和p_y$是像素级的</p><p> $x$：图像坐标</p></blockquote><p>反转：从图像坐标$x$和对应深度值$d_Z$沿光轴重建为3D模型点</p><blockquote><p><strong>光轴</strong>是<a href="https://zh.wikipedia.org/wiki/%E5%85%89%E5%AD%B8">光学</a>系统中一条假想的线，定义（在一次近似下）光学系统如何传导光线</p></blockquote><p>$$<br>\mathbf{X}&#x3D;\pi^{-1}(x, d_Z)&#x3D;d_Z\begin{bmatrix}<br> \frac{x-p_x}{f_x} \ \frac{y-p_y}{f_y} \ 1<br>\end{bmatrix}<br>\tag{19}<br>$$</p><p>使用齐次矩阵$_{C}T _M \in SE(3)$描述相机参考系C和模型参考系M之间的相对姿态</p><blockquote><p>SE(3) 是旋转加上位移， 也称欧式变换（Euclidean transformation），刚体变换（Rigid Transformation），一般我们用矩阵 <img src="https://www.zhihu.com/equation?tex=%5Cbegin%7Bbmatrix%7D+%5Cmathbf%7BR%7D++&+t++%5C%5C+%5Cmathbf%7B0%7D++&++1+%5Cend%7Bbmatrix%7D" class="lazyload" data-srcset="https://www.zhihu.com/equation?tex=%5Cbegin%7Bbmatrix%7D+%5Cmathbf%7BR%7D++&+t++%5C%5C+%5Cmathbf%7B0%7D++&++1+%5Cend%7Bbmatrix%7D" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="[公式]"> 来表示，其中 <img src="https://www.zhihu.com/equation?tex=%5Cmathbf%7BR%7D" class="lazyload" data-srcset="https://www.zhihu.com/equation?tex=%5Cmathbf%7BR%7D" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" alt="[公式]"> 为旋转， t 为位移，所以有6个自由度，3个旋转，3个位置。</p><p><img src="https://s3.bmp.ovh/imgs/2022/05/08/316ffabcc2615497.jpg" class="lazyload" data-srcset="https://s3.bmp.ovh/imgs/2022/05/08/316ffabcc2615497.jpg" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p></blockquote><p>对于一个三维模型点的变换，我们可以写出：<br>$$<br>_{C} \widetilde{X}  &#x3D; _{C}T _{MM} \widetilde{X}&#x3D;\begin{bmatrix}<br> _{C}R_M&amp; -{C}t_M \<br> 0 &amp; 1<br>\end{bmatrix}<br> \space  _{M}\widetilde{X}<br>\tag{20}<br>$$</p><blockquote><p> $_{C} \widetilde{X}$和$ \space  _{M}\widetilde{X}$ 分别是写入相机C和参考系模型参考系M中的3D模型点</p><p> $ _{C}R_M$和$-{C}t_M$是旋转矩阵和平移向量，定义从M到C的转换</p></blockquote><img src="https://s3.bmp.ovh/imgs/2022/05/08/64076aaa9fbca644.png" class="lazyload" data-srcset="https://s3.bmp.ovh/imgs/2022/05/08/64076aaa9fbca644.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw==" style="zoom:50%;" /><p>对于小的变化，使用角轴表示，这是一个最小的表示。 用指数映射，旋转矩阵写为<br>$$<br>\mathbf{R} &#x3D; exp([\mathbf{r}]_\times)&#x3D;\mathbf{I} + [\mathbf{r}]_\times +<br>\frac{1}{2!}[\mathbf{r}]_\times^{2}+<br>\frac{1}{3!}[\mathbf{r}]_\times^{3}+…<br>\tag{21}<br>$$</p><blockquote><p> $[\mathbf{r}]_\times$是斜对称矩阵,$\mathbf{r} \in R^3$</p></blockquote><p>忽略级数展开的高阶项，等式（21）可以线性化。然后，我们可以在相机参考系C中写入3D模型点的线性变化，如下所示：<br>$$<br>_C\widetilde{X}(\theta) &#x3D;<br>\begin{bmatrix}<br>  _CR_M&amp; Ct_M\<br>  0&amp;1<br>\end{bmatrix}<br>\begin{bmatrix}<br> \mathbf{I} + [\theta_r]_\times &amp; \theta _t \<br> 0 &amp; 1<br>\end{bmatrix}<br>\space _M \widetilde{X}<br>\tag{22}<br>$$</p><blockquote><p>$\theta_r \in R^3$ ：旋转变换</p><p>$\theta _t \in R^3$：平移变换</p><p>$\theta ^T&#x3D;[\theta _r^T,\theta _t^T]$：完变换向量</p></blockquote><p>改变模型参考系M的优点：</p><ol><li>由于对象的移动量通常比相机的移动量大得多，会更加自然</li><li>使&#x3D;&#x3D;拓展为使用多相机算法&#x3D;&#x3D;成为可能</li></ol><h4 id="3-2-Sparse-Viewpoint-Model"><a href="#3-2-Sparse-Viewpoint-Model" class="headerlink" title="3.2 Sparse Viewpoint Model"></a>3.2 Sparse Viewpoint Model</h4><p>为了创建这个模型，三维几何体从物体周围的<strong>若干$n_v$视点</strong>进行渲染</p><p>虚拟摄像机被放置在围绕物体的测地网格的顶点上</p><p>对于每一个渲染，$n_c个点 \mathbf{x_i} \in R^2$从模型轮廓上随机采样（2D上）</p><p>单位向量$\mathbf{n_i} \in R^2$近似垂直于每个点（法向量）</p><p>基于2D实体，关于模型参考系，3D向量被重建：<br>$$<br>_M \mathbf{\widetilde{X} }_i &#x3D;  _{M}T <em>C \mathbf{\widetilde{\pi } }^{-1}(x_i,d</em>{Zi}) \tag{23}<br>$$</p><p>$$<br>_M \mathbf{N}_i  &#x3D; _M\mathbf{R}_C \begin{bmatrix}<br> \mathbf{n} _i  \ 0<br>\end{bmatrix}  \tag{24}<br>$$</p><blockquote><p>$\mathbf{ \widetilde{\pi }}^{-1}$：表示三维模型点以齐次形式返回（他可以将$x和d_Z$（图像值和深度）映射为3D模型点 ）</p><p>$d_{Zi}$：渲染产生的深度值</p><p>$C$：表示虚拟摄像机的，参考系渲染就是从这里开始的</p><p>$_M\mathbf{v}&#x3D;_M \mathbf{R}_C \mathbf{e}_Z$：方向向量，从摄像机指向模型中心$\mathbf{e}_Z&#x3D;\begin{bmatrix} 0 &amp; 0 &amp; 1 \end{bmatrix}^T$</p></blockquote><p>计算的3D模型点、法向量、方向向量会被存储到每一个视图中</p><p>给定特定的姿势（$_M\mathbf{R}_C和_C\mathbf{t}_M$），渲染模型和计算轮廓的过程简化为找到最接近的预计算视图$i_v$：<br>$$<br>i_v &#x3D; \underset{i \in {1,…n_v}}{arg \space max}(_M \mathbf{v}_i^{T}\space _M \mathbf{R}_C \space _C \mathbf{t} _M ) \tag{25}<br>$$<br>然后将相应的3D模型点和法向量投影到图像中</p><p>请注意，在优化关节后验概率时，这种高效率尤其重要，因为每次迭代中姿势都会发生变化。</p><h4 id="3-3-Joint-Posterior-Probability"><a href="#3-3-Joint-Posterior-Probability" class="headerlink" title="3.3 Joint Posterior Probability"></a>3.3 Joint Posterior Probability</h4><p>结合稀疏视点模型与对应线模型，定义关于姿势变换的联合后验概率</p><p>计算之前需要先定义，对应线的位置的方向</p><p>为此，使用以下等式将最接近视图的稀疏视点模型中的3D模型点和法向量投影到图像中：分别为位置和方向<br>$$<br>\mathbf{c}_i &#x3D; \mathbf{\widetilde{\pi } }(_C \mathbf{T} _M \space _M\mathbf{\widetilde{X}}_i)<br>\tag{26}<br>$$</p><p>$$<br>\mathbf{n}_i \propto (_C \mathbf{R} _M \space _M \mathbf{N}<em>i)</em>{2\times1}<br>\tag{27}<br>$$</p><blockquote><p>法向量$\mathbf{n}_i$：被标准化为单位向量</p><p>$()_{2\times1}$：表示向量的前两个元素</p></blockquote><p>所有的对应线被定义后，我们能够变化当前姿势和关于姿势变换向量$\theta$计算轮廓线$d_i$。然后轮廓距离可以通过对应线中心$c_i$到投影后的3D模型点（变为2D）的距离计算：<br>$$<br>d_i(\mathbf{\theta}) &#x3D; \mathbf{n}_i^T(\mathbf{\pi}(_C \mathbf{X}_i(\mathbf{\theta}))-\mathbf{c}_i) \tag{28}<br>$$<br>三维模型点$X_i$与定义对应线的三维模型点$X_i$相同</p><p>3D模型点$_C \mathbf{X}_i$和轮廓距离$d_i$都依赖于<strong>当前姿势</strong>估计$_C \mathbf{T} _M$,这会和用于定义对应线时的姿势不同</p><p>带有变化后的轮廓距离的轮廓线展示如下：</p><p>(虚线是原点，虚线是基于姿势变换向量$\theta$当前估计的轮廓线)</p><p><img src="https://s3.bmp.ovh/imgs/2022/05/08/9cd6ec54392ad90b.png" class="lazyload" data-srcset="https://s3.bmp.ovh/imgs/2022/05/08/9cd6ec54392ad90b.png" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAP///////yH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p><p>假设对应线独立，并使用离散化尺度空间（2.3节），联合后验概率被计算如下：<br>$$<br>p(\mathbf{\theta} \space | \space \mathbf{D}) \propto \prod_{i&#x3D;1}^{n_c}p(d_{si}(\mathbf{\theta}) \space | \space \omega <em>{si},\mathbf{l}</em>{si})<br>\tag{29}<br>$$</p><blockquote><p>$\mathbf{D}$描述所有对应线的数据</p></blockquote><p>联合后验概率：描述了当前姿势估计将图像分割成前景区域（对应追踪目标）和后景区域的效果</p><h4 id="3-4-Optimization"><a href="#3-4-Optimization" class="headerlink" title="3.4 Optimization"></a>3.4 Optimization</h4><p>目标：最大化联合后验概率</p><p>方法：估计变化向量$\mathbf{\tilde{\theta}}$并迭代更新姿势</p><p>具体的计算（暂略）</p><p>结论：</p><ol><li>正则化参数对应对应先验概率，控制了我们对先前的姿势（与梯度和Hessian描述的当前估计相比）的信任程度</li><li>对于Hessian表示高度不确定性的方向，正则化有助于保持优化稳定，并避免没有足够数据支持的位置变化</li></ol><h4 id="3-5-Gradient-and-Hessian-Approximation"><a href="#3-5-Gradient-and-Hessian-Approximation" class="headerlink" title="3.5 Gradient and Hessian Approximation"></a>3.5 Gradient and Hessian Approximation</h4><p>梯度向量和Hessian矩阵的近似方式确保了快速收敛和高精度</p><p>为了计算对数后验函数所需的一阶和二阶导数，我们区分了全局优化和局部优化。我们提出了不同的局部优化近似方法，此外，我们要么应用全局优化，要么应用局部优化，并对所有对应线使用相同的导数定义，而不是混合使用</p><p>使用全局优化时，独立对应线的后验概率发布近似正态分布</p>]]></content>
      
      
      <categories>
          
          <category> 目标检测 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 实验室 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>music test</title>
      <link href="/2022/05/11/%E9%9F%B3%E4%B9%90%E6%B5%8B%E8%AF%95/"/>
      <url>/2022/05/11/%E9%9F%B3%E4%B9%90%E6%B5%8B%E8%AF%95/</url>
      
        <content type="html"><![CDATA[]]></content>
      
      
      <categories>
          
          <category> 测试 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 音乐 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Volantis 第一次使用</title>
      <link href="/2022/05/11/Volantis-%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8/"/>
      <url>/2022/05/11/Volantis-%E7%AC%AC%E4%B8%80%E6%AC%A1%E4%BD%BF%E7%94%A8/</url>
      
        <content type="html"><![CDATA[<h3 id="Hello-world！"><a href="#Hello-world！" class="headerlink" title="Hello world！"></a>Hello world！</h3>]]></content>
      
      
      
    </entry>
    
    
  
  
</search>
